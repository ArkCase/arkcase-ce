###################################################
# Get the analytical reports project and unzip it
###################################################

- name: Set reports version formatted
  set_fact:
    foia_analytical_reports_version_formatted: "{{ '-' ~ foia_analytical_reports_version if foia_analytical_reports_version != '' else '' }}"
    

- name: create install folder
  become: yes
  become_user: pentaho
  file:
    path: "{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}"
    state: directory  

- name: download FOIA analytical reports repository
  become: yes
  become_user: pentaho
  command: sshpass -e sftp -o StrictHostKeyChecking\=no -o UserKnownHostsFile\=/dev/null {{ sftp_arkcase_user }}@{{ sftp_service_base_url }}:{{ sftp_arkcase_folder }}/{{ item }}
  args:
    chdir: "{{ root_folder }}/install/pentaho"
  environment:
    SSHPASS: "{{ sftp_arkcase_password }}"
  loop:
    - foia-reports-dw{{ foia_analytical_reports_version_formatted }}.zip

- name: unzip repository
  become: yes
  become_user: pentaho
  unarchive:
    remote_src: yes
    src: "{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}.zip"
    dest: "{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}"

##########################################################
# Configure the Kettle job files and run the Kettle job.
# This will create and populate the data warehouse tables.
##########################################################

- name: get the encrypted password for the kettle job
  become: yes
  become_user: pentaho-pdi
  shell: "{{ root_folder }}/app/pentaho-pdi/data-integration/encr.sh -kettle '{{ rds_password | default(default_database_password) }}' | grep Encrypted"
  register: encr_password
  changed_when: false

- name: get the encrypted password for the cache clean jobs
  become: yes
  become_user: pentaho-pdi
  shell: "{{ root_folder }}/app/pentaho-pdi/data-integration/encr.sh -kettle '{{ arkcase_admin_password }}' | grep Encrypted"
  register: arkcase_admin_encr_password
  changed_when: false

- name: ensure shared database connection folder exists
  become: yes
  become_user: pentaho-pdi
  file:
    path: /home/pentaho-pdi/.kettle
    state: directory

- name: write shared database connection file
  become: yes
  become_user: pentaho-pdi
  template:
    backup: yes
    src: shared.xml
    dest: /home/pentaho-pdi/.kettle/shared.xml

- name: ensure the job has no internal schedule (should be unscheduled)
  become: yes
  become_user: pentaho
  lineinfile:
    backup: yes
    path: "{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}/foia-dw1.kjb"
    backrefs: yes
    regexp: "<repeat>Y</repeat>"
    line: "      <repeat>N</repeat>"

- name: find project files
  become: yes
  become_user: pentaho
  find: 
    paths: 
      - "{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}"
      - "{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}/dimensions"
      - "{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}/stages"
      - "{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}/reports"
      - "{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}/misc"
    file_type: file
    recurse: no
    excludes: 
      - "*~"
      - "*.zip"
  register: foia_dw_files

- name: update database configurations
  include_tasks: update_db_config.yml
  loop: "{{ foia_dw_files.files | map(attribute='path') | list }}"
  loop_control:
    loop_var: f

- name: update pentaho URLs to clear report cache
  become: yes
  become_user: pentaho
  lineinfile:
    backup: yes
    backrefs: yes
    path: "{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}/misc/FOIA_CDA_CLEAR_CACHE.ktr"
    regexp: "{{ item.regexp }}"
    line: "{{ item.line }}"
  loop:
    - regexp: "<nullif>http{{ ':' }}//localhost{{ ':' }}8080/pentaho/plugin/cda/api/clearCache</nullif>"
      line: "<nullif>https://{{ internal_host }}:2002/pentaho/plugin/cda/api/clearCache</nullif>"
    - regexp: "<httpLogin>242.matthew.maines</httpLogin>"
      line: "  <httpLogin>{{ ldap_user_prefix }}arkcase-admin</httpLogin>"
    - regexp: "<httpPassword>Encrypted 2be98afc81ac2978aac22ab798bb3aac0</httpPassword>"
      line: "  <httpPassword>{{ arkcase_admin_encr_password.stdout }}</httpPassword>"

- name: update pentaho URLs to clear Mondrian cache
  become: yes
  become_user: pentaho
  lineinfile:
    backup: yes
    backrefs: yes
    path: "{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}/misc/FOIA_MONDRIAN_CLEAR_CACHE.ktr"
    regexp: "{{ item.regexp }}"
    line: "{{ item.line }}"
  loop:
    - regexp: "<nullif>http{{ ':' }}//localhost{{ ':' }}8080/pentaho/api/system/refresh/mondrianSchemaCache</nullif>"
      line: "<nullif>https://{{ internal_host }}:2002/pentaho/api/system/refresh/mondrianSchemaCache</nullif>"
    - regexp: "<httpLogin>242.matthew.maines</httpLogin>"
      line: "  <httpLogin>{{ ldap_user_prefix }}arkcase-admin</httpLogin>"
    - regexp: "<httpPassword>Encrypted 2be98afc81ac2978aac22ab798bb3aac0</httpPassword>"
      line: "  <httpPassword>{{ arkcase_admin_encr_password.stdout }}</httpPassword>"

- name: setup path to arkcase config file
  become: yes
  become_user: pentaho
  lineinfile:
    backup: yes
    backrefs: yes
    path: "{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}/misc/VARIABLE_CONFIG.ktr"
    regexp: "{{ item.regexp }}"
    line: "{{ item.line }}"
  loop:
    - regexp: "<name>C{{ ':' }}\\Users\\marjan.stefanoski\\foia---reports-dw-1\\config\\arkcase_config.properties</name>"
      line: "<name>{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}/config/arkcase_config.properties</name>"

- name: setup Arkcase REST endpoints
  become: yes
  become_user: pentaho
  lineinfile:
    backup: yes
    backrefs: yes
    path: "{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}/config/arkcase_config.properties"
    regexp: "{{ item.regexp }}"
    line: "{{ item.line }}"
  loop:
    - regexp: "AGENCY_REST_ENDPOINT=https{{ ':' }}//acm-arkcase/arkcase/api/latest/service/config/lookups"
      line: "AGENCY_REST_ENDPOINT=https://{{ external_host }}/arkcase/api/latest/service/config/lookups"
    - regexp: "ARKCASE_USER=arkcase-admin@arkcase.org"
      line: "ARKCASE_USER={{ arkcase_admin_user }}@{{ ldap_user_domain }}"
    - regexp: "ARKCASE_PASS=AcMd3v$"
      line: "ARKCASE_PASS={{ arkcase_admin_password }}"
    - regexp: "TRUSTSTORE_PATH=~/\.arkcase/acm/private/arkcase\.ts"
      line: "TRUSTSTORE_PATH={{ java_trust_store }}"
    - regexp: "TRUSTSTORE_PASSWORD=password"
      line: "TRUSTSTORE_PASSWORD={{ java_trust_store_pass }}"

- name: run the job to create and populate the mondrian cubes
  become: yes
  become_user: pentaho-pdi
  command: 
    cmd: ./kitchen.sh -file://{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}/foia-dw1.kjb
    chdir: "{{ root_folder }}/app/pentaho-pdi/data-integration"

- name: set the cron environment so as to be able to run the job
  become: yes
  become_user: pentaho-pdi
  cron: 
    env: yes
    name: "{{ item.name }}"
    job: "{{ item.value }}"
  loop:
    - name: PATH
      value: "/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/pentaho-pdi/.local/bin:/home/pentaho-pdi/bin"
    - name: SHELL
      value: /bin/bash

- name: schedule the job to run every day at 2 AM
  become: yes
  become_user: pentaho-pdi
  cron:
    backup: yes
    name: "populate FOIA data warehouse tables"
    job: "{{ root_folder }}/app/pentaho-pdi/data-integration/kitchen.sh -file://{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}/foia-dw1.kjb"
    month: "*"
    weekday: "*"
    day: "*"
    hour: "2"
    minute: "0"
    disabled: no
    state: present

###################################################
# Create the JDBC and the Mondrian data sources 
###################################################

- name: list the data sources that already exist
  become: yes
  become_user: pentaho
  command: 
    cmd: 'wget --no-check-certificate -O {{ root_folder }}/install/pentaho/datasources-list.json --user={{ ldap_user_prefix }}arkcase-admin --password "{{ arkcase_admin_password }}" https://{{ internal_host }}:2002/pentaho/plugin/data-access/api/datasource/jdbc/connection'
    warn: no
  changed_when: false

- name: read the list of data sources
  become: yes
  become_user: pentaho
  command: cat {{ root_folder }}/install/pentaho/datasources-list.json
  register: data_source_list
  changed_when: false

- name: file to post to Pentaho to create the data source
  become: yes
  become_user: pentaho
  template:
    src: put_connection.json
    dest: "{{ root_folder }}/install/pentaho/put_connection.json"
  when: not '"MariaDB Local"' in data_source_list.stdout

# the ansible uri module causes a timeout for some reason but wget works fine
- name: create the ArkCase JDBC data source for analytical reports
  command: 
    cmd: 'wget --no-check-certificate --user={{ ldap_user_prefix }}arkcase-admin --password "{{ arkcase_admin_password }}" --post-file {{ root_folder }}/install/pentaho/put_connection.json --header="Content-Type: application/json" https://{{ internal_host }}:2002/pentaho/plugin/data-access/api/connection/add'
    warn: no
  register: create_datasource_rest_call
  when: not '"MariaDB Local"' in data_source_list.stdout

- name: upload the Mondrian schema
  become: yes
  become_user: pentaho
  command:
    cmd: 'curl -k -v -H "Content-Type: multipart/form-data" -X PUT -F uploadInput=@{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}/mondrian_schema/{{ foia_mondrian_schema_file }} -F overwrite=true -F xmlaEnabledFlag=false -F parameters="Datasource=MariaDB Local" -u {{ ldap_user_prefix }}arkcase-admin:{{ arkcase_admin_password }} https://{{ internal_host }}:2002/pentaho/plugin/data-access/api/datasource/analysis/catalog/{{ foia_mondrian_schema_file | replace(".xml", "") }}'
    warn: no

#########################################################
# Deploy the reports 
#########################################################

- name: import reports from the zip file archive
  command: "{{ root_folder }}/app/pentaho/pentaho-server/import-export.sh --import --url=https://{{ internal_host }}:2002/pentaho --username={{ ldap_user_prefix }}arkcase-admin --password='{{ arkcase_admin_password }}' --charset=UTF-8 --path=/public --file-path='{{ root_folder }}/install/pentaho/foia-reports-dw{{ foia_analytical_reports_version_formatted }}/reports/foia.zip' --permission=true --overwrite=true --retainOwnership=true"

